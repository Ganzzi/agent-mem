# Agent Mem Environment Configuration
# Copy this file to .env and update with your values

# ============================================================================
# Google Gemini API Configuration
# ============================================================================
GEMINI_API_KEY=your_google_gemini_api_key_here

# ============================================================================
# PostgreSQL Configuration
# ============================================================================
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_USER=agent_mem_user
POSTGRES_PASSWORD=agent_mem_password_change_me
POSTGRES_DB=agent_mem

# For testing
POSTGRES_TEST_DB=agent_mem_test

# ============================================================================
# Neo4j Configuration
# ============================================================================
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=neo4j_password_change_me
NEO4J_DATABASE=neo4j

# ============================================================================
# Ollama Configuration
# ============================================================================
OLLAMA_BASE_URL=http://localhost:11434
EMBEDDING_MODEL=nomic-embed-text
VECTOR_DIMENSION=768

# ============================================================================
# AI Agent Models (Google Gemini via Ollama)
# ============================================================================
MEMORY_UPDATE_AGENT_MODEL=google-gla:gemini-2.0-flash
MEMORIZER_AGENT_MODEL=google-gla:gemini-2.0-flash
MEMORY_RETRIEVE_AGENT_MODEL=google-gla:gemini-2.0-flash

# ============================================================================
# Memory Configuration
# ============================================================================
# Number of updates before consolidation
ACTIVE_MEMORY_UPDATE_THRESHOLD=5

# Importance score threshold for promotion to longterm
SHORTTERM_PROMOTION_THRESHOLD=0.7

# ============================================================================
# Docker Configuration (for docker-compose.yml)
# ============================================================================
# Path to Ollama data on host machine (for volume mount)
OLLAMA_HOST_VOLUME_PATH=./ollama_data

# Chunk configuration
CHUNK_SIZE=512
CHUNK_OVERLAP=50

# ============================================================================
# Search Configuration
# ============================================================================
SIMILARITY_THRESHOLD=0.7
BM25_WEIGHT=0.3
VECTOR_WEIGHT=0.7

# ============================================================================
# Development Settings
# ============================================================================
LOG_LEVEL=INFO
DEBUG=false
