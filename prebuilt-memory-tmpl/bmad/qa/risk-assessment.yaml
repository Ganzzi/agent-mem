template:
  id: "bmad.qa.risk-assessment.v1"
  name: "QA â€” Risk Assessment"
sections:
  - id: "assessment_context"
    title: "Assessment Context"
    description: "What's being assessed. Example: 'Pre-release risk assessment for AI prioritization feature. Beta launch planned March 30. Evaluating readiness and potential issues.'"
  - id: "technical_risks"
    title: "Technical Risks"
    description: "Technology-related risks. Example: 'High: ML service dependency (single point of failure). Medium: WebSocket scaling (untested >100 concurrent). Low: Database performance (well-tested).'"
  - id: "functional_risks"
    title: "Functional Risks"
    description: "Feature-related risks. Example: 'High: Algorithm accuracy varies (unpredictable user experience). Medium: Edge cases not fully tested. Low: Core functionality stable.'"
  - id: "user_impact_risks"
    title: "User Impact Risks"
    description: "Risks affecting users. Example: 'High: Poor priority suggestions damage trust. Medium: Performance degradation with large lists. Low: Minor UI glitches. Critical: Data loss (none identified).'"
  - id: "operational_risks"
    title: "Operational Risks"
    description: "Deployment and operations risks. Example: 'Medium: Rollback complexity (database schema changed). Low: Monitoring gaps. Medium: No runbook for ML service failures. Low: Support team training needed.'"
  - id: "mitigation_strategies"
    title: "Mitigation Strategies"
    description: "How to reduce risks. Example: 'ML dependency: Add fallback to rule-based priorities. Scaling: Feature flag for gradual rollout. Algorithm accuracy: Feedback loop for improvements. Rollback: Test rollback procedure.'"
  - id: "risk_matrix"
    title: "Risk Matrix"
    description: "Risks by likelihood and impact. Example: 'High/High: None. High/Medium: Algorithm accuracy, ML service failure. Medium/Medium: Scaling, edge cases. Low/Low: UI polish, support training.'"
  - id: "go_no_go_recommendation"
    title: "Launch Recommendation"
    description: "Recommendation with rationale. Example: 'Recommendation: GO with caution. Ship to beta with 10% rollout. Monitor closely for 48 hours. Mitigation: Feature flag, fallback enabled, support on standby. Full rollout after beta validation.'"
  - id: "monitoring_plan"
    title: "Monitoring & Response Plan"
    description: "How to track and respond to issues. Example: 'Monitor: Error rates, ML latency, user feedback, adoption rate. Alert thresholds: >5% errors, >1s latency. Response: Engineering on-call, 2-hour SLA, rollback ready.'"
metadata:
  usage: "risk-assessment"
  priority: "high"
  workflow: "quality-gate"
